name: Performance Tests

on:
  workflow_dispatch:
    inputs:
      base_url:
        description: 'API Base URL (default: http://localhost:3000)'
        required: false
        default: 'http://localhost:3000'
  push:
    branches: [main]

jobs:
  performance-tests:
    name: Run Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10

    env:
      DATABASE_HOST: ${{ vars.DATABASE_HOST }}
      DATABASE_PORT: ${{ vars.DATABASE_PORT }}
      DATABASE_USER: ${{ vars.DATABASE_USER }}
      DATABASE_PASSWORD: ${{ secrets.DATABASE_PASSWORD }}
      DATABASE_NAME: ${{ vars.DATABASE_NAME }}
      BASE_URL: ${{ github.event.inputs.base_url || 'http://localhost:3000' }}
      HMAC_SECRET: ${{ secrets.HMAC_SECRET || 'test' }}
      LOAD_PROFILE: ${{ github.event.inputs.load_profile || 'easy' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build and start Docker services
        run: |
          docker compose up -d --build
          echo "Waiting for services to be ready..."

      - name: Wait for API to be healthy
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:3000/health > /dev/null 2>&1; do 
            echo "Waiting for API to be ready..."
            sleep 2
          done'
          echo "API is ready!"

      - name: Setup database schema
        run: npm run db:push

      - name: Seed database
        run: npm run db:seed

      - name: Wait for services to be fully ready
        run: |
          sleep 5
          echo "Services should be ready now"

      - name: Install jq for metrics parsing
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Run K6 performance tests (Process endpoint)
        run: |
          echo "ðŸš€ Starting K6 performance test - Process endpoint"
          echo "   BASE_URL: $BASE_URL"
          echo "   LOAD_PROFILE: $LOAD_PROFILE"
          echo ""
          
          docker run --rm -i --network host \
            -v $(pwd):/scripts \
            -e BASE_URL="$BASE_URL" \
            -e HMAC_SECRET="$HMAC_SECRET" \
            -e LOAD_PROFILE="$LOAD_PROFILE" \
            grafana/k6 run \
            --out json=results-process.json \
            /scripts/tests/performance/process-endpoint.js

      - name: Run K6 performance tests (RTP endpoint)
        run: |
          echo "ðŸš€ Starting K6 performance test - RTP endpoint"
          echo "   BASE_URL: $BASE_URL"
          echo "   LOAD_PROFILE: $LOAD_PROFILE"
          echo ""
          
          docker run --rm -i --network host \
            -v $(pwd):/scripts \
            -e BASE_URL="$BASE_URL" \
            -e LOAD_PROFILE="$LOAD_PROFILE" \
            grafana/k6 run \
            --out json=results-rtp.json \
            /scripts/tests/performance/rtp-endpoint.js || true

      - name: Upload K6 results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: k6-results
          path: |
            results-process.json
            results-rtp.json
          retention-days: 90

      - name: Display performance summary
        if: always()
        run: |
          echo "## Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Function to extract and display metrics from a results file
          display_metrics() {
            local file=$1
            local title=$2
            
            if [ ! -f "$file" ]; then
              echo "âš ï¸ $title: No results file found" >> $GITHUB_STEP_SUMMARY
              return
            fi
            
            echo "### $title" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if command -v jq &> /dev/null; then
              REQUESTS=$(jq -r '.metrics.http_reqs.values.count // "N/A"' "$file" 2>/dev/null || echo "N/A")
              RATE=$(jq -r '.metrics.http_reqs.values.rate // "N/A"' "$file" 2>/dev/null || echo "N/A")
              P95=$(jq -r '.metrics.http_req_duration.values["p(95)"] // .metrics.http_req_duration.values.p95 // "N/A"' "$file" 2>/dev/null || echo "N/A")
              P99=$(jq -r '.metrics.http_req_duration.values["p(99)"] // .metrics.http_req_duration.values.p99 // "N/A"' "$file" 2>/dev/null || echo "N/A")
              ERROR_RATE=$(jq -r '.metrics.http_req_failed.values.rate // "N/A"' "$file" 2>/dev/null || echo "N/A")
              
              echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
              echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
              echo "| Total Requests | $REQUESTS |" >> $GITHUB_STEP_SUMMARY
              echo "| Request Rate | $RATE req/s |" >> $GITHUB_STEP_SUMMARY
              echo "| p95 Latency | $P95 ms |" >> $GITHUB_STEP_SUMMARY
              echo "| p99 Latency | $P99 ms |" >> $GITHUB_STEP_SUMMARY
              echo "| Error Rate | $ERROR_RATE |" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            else
              echo "âš ï¸ jq not installed - cannot parse detailed metrics" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          }
          
          display_metrics "results-process.json" "Process Endpoint"
          display_metrics "results-rtp.json" "RTP Endpoint"

      - name: Show Docker logs on failure
        if: failure()
        run: |
          echo "=== API Logs ==="
          docker compose logs api --tail 100
          echo "=== Database Logs ==="
          docker compose logs db --tail 50
          echo "=== Docker PS ==="
          docker ps -a

      - name: Stop Docker services
        if: always()
        run: docker compose down -v

